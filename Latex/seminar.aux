\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\citation{RHC}
\citation{FSI}
\citation{ABOUT_JAPANESE}
\citation{RHC}
\citation{RHC}
\citation{MACHINE_LEARNING}
\citation{MACHINE_LEARNING}
\citation{MACHINE_LEARNING}
\citation{MACHINE_LEARNING}
\babel@aux{ngerman}{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Einleitung}{X-1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}Grundlagen}{X-1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Konvolutionale Neuronale Netze}{X-1}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Aufbau einer konvolutionalen Schicht mit Schrittweite eins und Zero Padding \cite  [S.362]{MACHINE_LEARNING}}}{X-1}{}\protected@file@percent }
\newlabel{bild1}{{1}{X-1}}
\citation{MACHINE_LEARNING}
\citation{MACHINE_LEARNING}
\citation{MACHINE_LEARNING}
\citation{MACHINE_LEARNING}
\citation{MACHINE_LEARNING}
\citation{MACHINE_LEARNING}
\citation{MACHINE_LEARNING}
\citation{TRANSFORMERS}
\citation{TRANSFORMERS}
\citation{MACHINE_LEARNING}
\citation{TRANSFORMERS}
\citation{RNN_ATTENTION}
\citation{RNN_ATTENTION}
\citation{RNN_ATTENTION}
\citation{VIT}
\citation{TRANSFORMERS}
\citation{VIT}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Aufbau eines \emph  {CNN} mit drei Schichten und vielen Feature Maps \cite  [S.365]{MACHINE_LEARNING}}}{X-2}{}\protected@file@percent }
\newlabel{bild2}{{2}{X-2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}Vision Transformer}{X-2}{}\protected@file@percent }
\citation{VIT}
\citation{VIT}
\citation{IMAGENET}
\citation{JFT}
\citation{RHC}
\citation{RHC}
\citation{ETL}
\citation{RHC}
\citation{ETL_FORMATS}
\citation{RHC}
\citation{RHC}
\citation{RHC}
\citation{RHC}
\citation{RHC}
\citation{RHC}
\citation{RHC}
\citation{RHC}
\citation{ETL}
\citation{RHC}
\citation{RHC}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Beispiel für erlernte Attention zwischen einem englischen und französischen Satz \cite  [S.6]{RNN_ATTENTION}}}{X-3}{}\protected@file@percent }
\newlabel{bildAttention}{{3}{X-3}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Übersicht der Daten}{X-3}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Aufbau des ersten Datensatz nach \cite  {RHC}}}{X-3}{}\protected@file@percent }
\newlabel{data_tsai}{{I}{X-3}}
\citation{RHC}
\citation{MACHINE_LEARNING}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Grundsätzlicher Aufbau eines Vision Transformers \cite  [S.3]{VIT}}}{X-4}{}\protected@file@percent }
\newlabel{vitimg}{{4}{X-4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Extrahierte und invertierte Schriftzeichen aus der \emph  {ETL Character Database} \cite  [S.1]{RHC}}}{X-4}{}\protected@file@percent }
\newlabel{kana}{{5}{X-4}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Aufbau des zweiten Datensatz als Gesamtauswahl der \emph  {ETL Character Database}}}{X-4}{}\protected@file@percent }
\newlabel{data_total}{{II}{X-4}}
\citation{RHC}
\citation{RHC}
\citation{RHC}
\citation{RHC}
\citation{RHC}
\citation{RHC}
\citation{RHC}
\citation{simonyan2015deep}
\citation{simonyan2015deep}
\citation{simonyan2015deep}
\citation{RHC}
\citation{RHC}
\citation{simonyan2015deep}
\citation{RHC}
\citation{RHC}
\citation{RHC}
\citation{RHC}
\citation{MACHINE_LEARNING}
\citation{RHC}
\citation{MACHINE_LEARNING}
\citation{vgg_keras}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Transformationen des Kanji \textit  {zwei Stück}}}{X-5}{}\protected@file@percent }
\newlabel{rot}{{6}{X-5}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Eingesetzte Modelle}{X-5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-A}}VGGNet}{X-5}{}\protected@file@percent }
\citation{resnet}
\citation{resnet}
\citation{RHC}
\citation{resnet}
\citation{resnet}
\citation{resnet}
\citation{resnet_keras}
\citation{resnetv2}
\citation{VIT}
\citation{VIT}
\citation{VIT}
\citation{git_vit}
\citation{RHC}
\citation{RHC}
\citation{RHC}
\citation{RHC}
\citation{MACHINE_LEARNING}
\citation{RHC}
\citation{keras_vgg}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Beispiel einer Abkürzungsverbindung über zwei Schichten \cite  [S.2]{resnet}}}{X-6}{}\protected@file@percent }
\newlabel{res}{{7}{X-6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-B}}ResNet}{X-6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-C}}Vision Transformer}{X-6}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Vordefinierte Varianten der \emph  {Vision Transformer} Modelle \cite  [S.5]{VIT}}}{X-6}{}\protected@file@percent }
\newlabel{vit_sizes}{{III}{X-6}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Ergebnisse}{X-6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-A}}VGGNet}{X-6}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Genauigkeit und F1-Scores der \emph  {VGGNet} Modelle für den Tsai-Datensatz in Prozent}}{X-6}{}\protected@file@percent }
\newlabel{vgg_ergebnis_tsai}{{IV}{X-6}}
\citation{RHC}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Genutzte \emph  {VGGNet} Architekturen im Paper von Charlie Tsai \cite  [S.3]{RHC}}}{X-7}{}\protected@file@percent }
\newlabel{vggnet}{{8}{X-7}}
\@writefile{lot}{\contentsline {table}{\numberline {V}{\ignorespaces Genauigkeit und F1-Scores der VGGNet Modelle für den kompletten Datensatz in Prozent}}{X-7}{}\protected@file@percent }
\newlabel{vgg_ergebnis_full}{{V}{X-7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-B}}ResNet}{X-7}{}\protected@file@percent }
\citation{resnet_keras}
\citation{keras_app}
\citation{IMAGENET}
\citation{JFT}
\citation{huggingface}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Verlust des \emph  {M7-2} Modells während des Trainings über den kompletten Datensatz.}}{X-8}{}\protected@file@percent }
\newlabel{loss}{{9}{X-8}}
\@writefile{lot}{\contentsline {table}{\numberline {VI}{\ignorespaces Genauigkeit und F1-Scores der \emph  {ResNet} Modelle für den Tsai-Datensatz in Prozent}}{X-8}{}\protected@file@percent }
\newlabel{resnet_ergebnis_tsai}{{VI}{X-8}}
\@writefile{lot}{\contentsline {table}{\numberline {VII}{\ignorespaces Genauigkeit und F1-Scores der \emph  {ResNet} Modelle für den kompletten Datensatz in Prozent}}{X-8}{}\protected@file@percent }
\newlabel{resnet_ergebnis_full}{{VII}{X-8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-C}}Vision Transformer}{X-8}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {VIII}{\ignorespaces Genauigkeit und F1-Scores der \emph  {ViT} Modelle für den Tsai-Datensatz in Prozent}}{X-8}{}\protected@file@percent }
\newlabel{vit_ergebnis_tsai}{{VIII}{X-8}}
\@writefile{lot}{\contentsline {table}{\numberline {IX}{\ignorespaces Genauigkeit und F1-Scores der \emph  {ViT} Modelle für den kompletten Datensatz in Prozent}}{X-8}{}\protected@file@percent }
\newlabel{vit_ergebnis_full}{{IX}{X-8}}
\bibstyle{IEEEtran}
\bibdata{seminar}
\bibcite{FSI}{1}
\bibcite{ABOUT_JAPANESE}{2}
\bibcite{RHC}{3}
\bibcite{MACHINE_LEARNING}{4}
\bibcite{TRANSFORMERS}{5}
\bibcite{RNN_ATTENTION}{6}
\bibcite{VIT}{7}
\bibcite{IMAGENET}{8}
\bibcite{JFT}{9}
\bibcite{ETL}{10}
\bibcite{ETL_FORMATS}{11}
\bibcite{simonyan2015deep}{12}
\bibcite{vgg_keras}{13}
\bibcite{resnet}{14}
\bibcite{resnet_keras}{15}
\bibcite{resnetv2}{16}
\bibcite{git_vit}{17}
\bibcite{keras_vgg}{18}
\bibcite{keras_app}{19}
\bibcite{huggingface}{20}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Fazit}{X-9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VII}Ausblick}{X-9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Literatur}{X-9}{}\protected@file@percent }
\gdef \@abspage@last{10}
